{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81dd741",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e90f1400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.display import IFrame, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "628f9f71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install xgboost\n",
    "!pip install lightgbm\n",
    "!pip install catboost\n",
    "!pip install scikit-optimize\n",
    "!pip install pickle\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b91d7e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "from functools import wraps\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "\n",
    "from numpy import hstack\n",
    "\n",
    "from IPython.display import IFrame\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "from plot_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c172573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, mutual_info_classif\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold, cross_val_score, GridSearchCV, train_test_split\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a45d5dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'C:/Users/yaass/OneDrive/Bureau/Parser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f0dfeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(\"INFO\")\n",
    "handler = logging.StreamHandler()\n",
    "logger.addHandler(handler)\n",
    "#https://gist.github.com/bradmontgomery/bd6288f09a24c06746bbe54afe4b8a82\n",
    "\n",
    "def timed(func):\n",
    "    \"\"\"This decorator prints the execution time for the decorated function.\"\"\"\n",
    "\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        logger.info(\"EXECUTION TIME : {} ran in {}s\".format(func.__name__, round(end - start, 2)))\n",
    "        return result\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def pickle_results(results, file, path='nested-cv-results'):\n",
    "    file_path = os.path.join(path, file)\n",
    "    pickle.dump(favorite_color, open( file_path, \"wb\" ), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def unpickle_results(file, path='nested-cv-results'):\n",
    "    file_path = os.path.join(path, file)\n",
    "    return pickle.load(open( file_path, \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e9fe763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(folder_path, file_name, index_value = 'md5'):\n",
    "    df = pd.read_csv(os.path.join(folder_path, file_name), index_col=index_value)\n",
    "    return df\n",
    "\n",
    "def print_proportion(df, label = 'label'):\n",
    "    print('Proportion : {:.2f}%'.format(100*sum(df.label)/len(df)))\n",
    "\n",
    "def create_X_y(folder_path, file_name, drop_null_columns=False, index_value = 'md5'):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    df = pd.read_csv(file_path, index_col = index_value)\n",
    "    X = df.drop('label', axis=1)\n",
    "    #X = df.drop(['label', 'sublabel'], axis=1)\n",
    "    if drop_null_columns == True:\n",
    "        X = X.drop(get_null_columns(X), axis=1)\n",
    "    y = df['label']\n",
    "    return shuffle(X, y)\n",
    "\n",
    "def create_X_y_(df, drop_null_columns=False, index_value = 'md5'):\n",
    "    X = df.drop('label', axis=1)\n",
    "    #X = df.drop(['label', 'sublabel'], axis=1)\n",
    "    if drop_null_columns == True:\n",
    "        X = X.drop(get_null_columns(X), axis=1)\n",
    "    y = df['label']\n",
    "    return shuffle(X, y)\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=2)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "def k_best_selection_(X, y, select_function=f_classif, k=10):\n",
    "    selector = SelectKBest(select_function, k=k).fit(X, y)\n",
    "    selected_columns_indices = selector.get_support(indices=True)\n",
    "    selected_df = X.iloc[:,selected_columns_indices]\n",
    "    selected_columns = selected_df.columns.tolist()\n",
    "    return selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2665eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timed\n",
    "def score_model_dataset(df, model):\n",
    "    X, y = create_X_y_(df)\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def join_dfs(dfs, labels=['label']):\n",
    "    joined = dfs[0]\n",
    "    for df in dfs[1:]:\n",
    "        joined = joined.join(df.drop(labels, axis=1)).fillna(0)\n",
    "    return joined\n",
    "\n",
    "\n",
    "def retrieve_subset(original_df, X, y = None, label='label', features_only=False):\n",
    "    filtered_columns = original_df.columns.tolist()\n",
    "    filtered_columns.remove(label)\n",
    "    if features_only == False :\n",
    "        filtered_index = original_df.index.intersection(X.index)\n",
    "        X_new = X.loc[filtered_index, filtered_columns]\n",
    "        y_new = y.loc[filtered_index]\n",
    "        return X_new, y_new\n",
    "    else :\n",
    "        X_new = X.loc[:, filtered_columns]\n",
    "        return X_new\n",
    "    \n",
    "    \n",
    "def prepare_datasets(original_dfs, X_train_full, X_test, y_train_full, y_test, test_size = 0.4):\n",
    "    datasets = []\n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(X_train_full, y_train_full, test_size = test_size, random_state = 1)\n",
    "    for df in original_dfs:\n",
    "        dataset = dict()\n",
    "        dataset['train'] = retrieve_subset(df, X_train, y_train)\n",
    "        dataset['eval'] = ( retrieve_subset(df, X_eval, features_only=True), y_eval )\n",
    "        dataset['test'] = ( retrieve_subset(df, X_test, features_only=True), y_test )\n",
    "        datasets.append(dataset)\n",
    "    return datasets\n",
    "    \n",
    "    \n",
    "def fit_ensemble(models, datasets):\n",
    "    X_meta = list()\n",
    "    for model, dataset in zip(models, datasets):\n",
    "        model.fit(*dataset['train'])\n",
    "        y_pred = model.predict(dataset['eval'][0])\n",
    "        y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "        X_meta.append(y_pred)\n",
    "    X_meta = np.hstack(X_meta)\n",
    "    blender = LogisticRegression()\n",
    "    blender.fit(X_meta, dataset['eval'][1])\n",
    "    return blender\n",
    "\n",
    "\n",
    "def predict_ensemble(models, blender, datasets):\n",
    "    X_meta = list()\n",
    "    for model, dataset in zip(models, datasets):\n",
    "        y_pred = model.predict(dataset['test'][0])\n",
    "        y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "        X_meta.append(y_pred)\n",
    "    X_meta = np.hstack(X_meta)\n",
    "    return blender.predict(X_meta)\n",
    "\n",
    "\n",
    "def get_blender_accuracy(original_dfs, X_train_full, X_test, y_train_full, y_test, models):\n",
    "    datasets = prepare_datasets(original_dfs, X_train_full, X_test, y_train_full, y_test, test_size = 0.4)\n",
    "    blender = fit_ensemble(models, datasets)\n",
    "    y_pred = predict_ensemble(models, blender, datasets)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "293f119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gb_models():\n",
    "    models = dict()\n",
    "    models['Gradient Boosting'] = GradientBoostingClassifier()\n",
    "    models['XGBoost'] = XGBClassifier()\n",
    "    models['LightGBM'] = LGBMClassifier()\n",
    "    models['CatBoost'] = CatBoostClassifier()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80e3881",
   "metadata": {},
   "source": [
    "### API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bcf7d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3761, 304)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_1 = 'onehot_encoded_apistats_dataset.csv'\n",
    "\n",
    "oh_apis = get_data(folder_path, file_name_1)\n",
    "\n",
    "oh_apis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09c00656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion : 58.23%\n"
     ]
    }
   ],
   "source": [
    "print_proportion(oh_apis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1c31dfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EXECUTION TIME : score_model_dataset ran in 10.24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9467353782192374"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute api cross-validation accuracy scores\n",
    "api_scores = score_model_dataset(oh_apis, RandomForestClassifier())\n",
    "np.mean(api_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ae15ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EXECUTION TIME : score_model_dataset ran in 12.34s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.945936800421393"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_scores_ = score_model_dataset(oh_apis, ExtraTreesClassifier())\n",
    "np.mean(api_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40bf6a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXECUTION TIME : score_model_dataset ran in 24.66s\n",
      "Gradient Boosting : 0.9172190398254227\n",
      "EXECUTION TIME : score_model_dataset ran in 60.18s\n",
      "XGBoost : 0.9451375171661305\n",
      "EXECUTION TIME : score_model_dataset ran in 11.25s\n",
      "LightGBM : 0.9447850236093083\n",
      "EXECUTION TIME : score_model_dataset ran in 296.85s\n",
      "CatBoost : 0.941149801531313\n"
     ]
    }
   ],
   "source": [
    "for name, model in get_gb_models().items():\n",
    "    api_scores_ = score_model_dataset(oh_apis, model)\n",
    "    print(f'{name} : {np.mean(api_scores_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0005ac7c",
   "metadata": {},
   "source": [
    "**Variable selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b57b58bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_classif : 0.9425661248753694\n",
      "chi2 : 0.9005589574279964\n",
      "mutual_info_classif : 0.9387561845100362\n"
     ]
    }
   ],
   "source": [
    "for selector_func in [f_classif, chi2, mutual_info_classif]:\n",
    "    pipe = Pipeline(steps=[('selector', SelectKBest(selector_func, k=150)), ('clf', RandomForestClassifier())])\n",
    "    api_selected_scores = score_model_dataset(oh_apis, pipe)\n",
    "    print(f'{selector_func.__name__} : {np.mean(api_selected_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "410c880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_X_y_(oh_apis)\n",
    "api_k_best_cols = k_best_selection_(X, y, f_classif, k=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d275ae0",
   "metadata": {},
   "source": [
    "### DLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df3d79fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3162, 2242)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_2 = 'onehot_encoded_dll_dataset.csv'\n",
    "\n",
    "dll_loaded = get_data(folder_path, file_name_2)\n",
    "\n",
    "dll_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af0d6a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion : 58.82%\n"
     ]
    }
   ],
   "source": [
    "print_proportion(dll_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25a39af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXECUTION TIME : score_model_dataset ran in 15.37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8678043764724672"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute dll cross-validation accuracy scores\n",
    "dll_scores = score_model_dataset(dll_loaded, RandomForestClassifier())\n",
    "np.mean(dll_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89d02520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXECUTION TIME : score_model_dataset ran in 167.58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.878773842324535"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost doesnt accept some characters in column names\n",
    "import re\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "\n",
    "dll_loaded.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in dll_loaded.columns.values]\n",
    "\n",
    "#compute dll cross-validation accuracy scores\n",
    "dll_scores_ = score_model_dataset(dll_loaded, XGBClassifier())\n",
    "np.mean(dll_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68428fd3",
   "metadata": {},
   "source": [
    "**Variable Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "433ee0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_classif : 0.8721312675531421\n",
      "chi2 : 0.8535685287971355\n",
      "mutual_info_classif : 0.8377507354017756\n"
     ]
    }
   ],
   "source": [
    "for selector_func in [f_classif, chi2, mutual_info_classif]:\n",
    "    pipe = Pipeline(steps=[('selector', SelectKBest(selector_func, k=150)), ('clf', RandomForestClassifier())])\n",
    "    dll_selected_scores = score_model_dataset(dll_loaded, pipe)\n",
    "    print(f'{selector_func.__name__} : {np.mean(dll_selected_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8ebef729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_classif : 0.8752878382515408\n",
      "chi2 : 0.8733901023572788\n"
     ]
    }
   ],
   "source": [
    "for selector_func in [f_classif, chi2]:\n",
    "    pipe = Pipeline(steps=[('selector', SelectKBest(selector_func, k=230)), ('clf', RandomForestClassifier())])\n",
    "    dll_selected_scores = score_model_dataset(dll_loaded, pipe)\n",
    "    print(f'{selector_func.__name__} : {np.mean(dll_selected_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "29371e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_X_y_(dll_loaded)\n",
    "dll_k_best_cols = k_best_selection_(X, y, f_classif, k=230)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c934c9d1",
   "metadata": {},
   "source": [
    "### PE Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5692d926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4308, 795)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_3 = 'pe_entropy_dataset.csv'\n",
    "\n",
    "pe_imports = get_data(folder_path, file_name_3)\n",
    "\n",
    "if 'sublabel' in pe_imports.columns.tolist():\n",
    "    pe_imports.drop('sublabel', axis=1, inplace=True)\n",
    "\n",
    "pe_imports.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b709affd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion : 60.35%\n"
     ]
    }
   ],
   "source": [
    "print_proportion(pe_imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8eb79b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.902198240975557"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute pe_imports cross-validation accuracy scores\n",
    "pe_imports_scores = score_model_dataset(pe_imports, RandomForestClassifier())\n",
    "np.mean(pe_imports_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef892682",
   "metadata": {},
   "source": [
    "## Joining Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dfdbca",
   "metadata": {},
   "source": [
    "### API and DLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "99b7fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dfs = [oh_apis, dll_loaded]\n",
    "\n",
    "joined_ = join_dfs(original_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe8f20a",
   "metadata": {},
   "source": [
    "#### Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b98dcdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "joining_scores = score_model_dataset(joined_, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018bb143",
   "metadata": {},
   "source": [
    "**Joining Variable Selected Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7390da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dfs_vs = [oh_apis[api_k_best_cols+['label']], dll_loaded[dll_k_best_cols+['label']]]\n",
    "\n",
    "joined_vs = join_dfs(original_dfs_vs)\n",
    "\n",
    "joining_scores_vs = score_model_dataset(joined_vs, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e10f10",
   "metadata": {},
   "source": [
    "#### Blending"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2760bcb",
   "metadata": {},
   "source": [
    "*Train-Test-Split*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4381b2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_X_y_(joined_)\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size = 0.1, random_state = 1)\n",
    "\n",
    "models = [RandomForestClassifier(), RandomForestClassifier()]\n",
    "\n",
    "score = get_blender_accuracy(original_dfs, X_train_full, X_test, y_train_full, y_test, models)\n",
    "\n",
    "print('Blending Accuracy: %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4efefb3",
   "metadata": {},
   "source": [
    "*Cross-validation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d7c60210",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "models = [RandomForestClassifier(), RandomForestClassifier()]\n",
    "\n",
    "blending_scores = []\n",
    "\n",
    "X, y = create_X_y_(joined_)\n",
    "\n",
    "for train_index, test_index in CV.split(X, y):\n",
    "    X_train_full, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    y_train_full, y_test = y[train_index], y[test_index]\n",
    "    score = get_blender_accuracy(original_dfs, X_train_full, X_test, y_train_full, y_test, models)\n",
    "    blending_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6602cd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"600\"\n",
       "            src=\"joined/evaluation_joined_api_dll.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1cb331b9ac0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plot_evaluation_boxplots([api_scores, dll_scores, blending_scores, joining_scores, joining_scores_vs], \n",
    "                               names = ['API', 'DLL', 'Blended', 'Joined All', 'Joined Selected'], \n",
    "                               title = 'Model Performance on joined \"apistats\" and \"dll\" Data', \n",
    "                               y_axis = 'Accuracy')\n",
    "\n",
    "figure_path = 'joined/evaluation_joined_api_dll.html'\n",
    "\n",
    "save_figures_to_html(figure_path, [fig])\n",
    "\n",
    "IFrame(figure_path, width=900, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f243713f",
   "metadata": {},
   "source": [
    "### API and PE Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fd577a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dfs = [pe_imports, oh_apis]\n",
    "\n",
    "joined = join_dfs(original_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3243cd16",
   "metadata": {},
   "source": [
    "#### Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "821d9f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "joining_scores = score_model_dataset(joined, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46c7e86",
   "metadata": {},
   "source": [
    "#### Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "78a60159",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "models = [RandomForestClassifier(), RandomForestClassifier()]\n",
    "\n",
    "blending_scores = []\n",
    "\n",
    "X, y = create_X_y_(joined)\n",
    "\n",
    "for train_index, test_index in CV.split(X, y):\n",
    "    X_train_full, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    y_train_full, y_test = y[train_index], y[test_index]\n",
    "    score = get_blender_accuracy(original_dfs, X_train_full, X_test, y_train_full, y_test, models)\n",
    "    blending_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c2cd3033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"600\"\n",
       "            src=\"joined/evaluation_joined_api_pe_imports.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x29b0ff05af0>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plot_evaluation_boxplots([api_scores, pe_imports_scores, blending_scores, joining_scores], \n",
    "                               names = ['API', 'PE Imports', 'Blended', 'Joined'], \n",
    "                               title = 'Model Performance on joined \"apistats\" and \"pe imports\" Data', \n",
    "                               y_axis = 'Accuracy')\n",
    "\n",
    "figure_path = 'joined/evaluation_joined_api_pe_imports.html'\n",
    "\n",
    "save_figures_to_html(figure_path, [fig])\n",
    "\n",
    "IFrame(figure_path, width=900, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a8da4a",
   "metadata": {},
   "source": [
    "### API, DLL and PE Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a25c1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dfs = [oh_apis, dll_loaded, pe_imports]\n",
    "\n",
    "joined = join_dfs(original_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "125626c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3761, 3339)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8049c60e",
   "metadata": {},
   "source": [
    "**Joining**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54f25475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9571921383825271"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joining_scores = score_model_dataset(joined, RandomForestClassifier())\n",
    "np.mean(joining_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f41c4a6",
   "metadata": {},
   "source": [
    "**Blending**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22206c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "models = [RandomForestClassifier(), RandomForestClassifier(), RandomForestClassifier()]\n",
    "\n",
    "blending_scores = []\n",
    "\n",
    "X, y = create_X_y_(joined)\n",
    "\n",
    "for train_index, test_index in CV.split(X, y):\n",
    "    X_train_full, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    y_train_full, y_test = y[train_index], y[test_index]\n",
    "    score = get_blender_accuracy(original_dfs, X_train_full, X_test, y_train_full, y_test, models)\n",
    "    blending_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d940370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"600\"\n",
       "            src=\"joined/evaluation_joined_api_dll_pe_imports.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1cb32152a90>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plot_evaluation_boxplots([api_scores, dll_scores, pe_imports_scores, blending_scores, joining_scores], \n",
    "                               names = ['API', 'DLL', 'PE Imports', 'Blended', 'Joined'], \n",
    "                               title = 'Model Performance on joined \"apistats\", \"dll\" and \"pe imports\" Data', \n",
    "                               y_axis = 'Accuracy')\n",
    "\n",
    "figure_path = 'joined/evaluation_joined_api_dll_pe_imports.html'\n",
    "\n",
    "save_figures_to_html(figure_path, [fig])\n",
    "\n",
    "IFrame(figure_path, width=900, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8483ad82",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with nested cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bd26636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_models():\n",
    "    models = dict()\n",
    "    models['RF'] = RandomForestClassifier()\n",
    "    models['ExRF'] = ExtraTreesClassifier()\n",
    "    models['AdaBoost'] = AdaBoostClassifier()\n",
    "    #models['GB'] = GradientBoostingClassifier()\n",
    "    models['XGBoost'] = XGBClassifier(objective = 'binary:logistic', eval_metric = 'logloss', silent=1, tree_method='approx')\n",
    "    models['LightGBM'] = LGBMClassifier(objective='binary', metric='binary_logloss', verbose=0)\n",
    "    models['CatBoost'] = CatBoostClassifier(thread_count=2, loss_function='Logloss', od_type = 'Iter', verbose= False)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c062eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_params['GB'] = {\n",
    "        'loss' : Categorical(['deviance']), #['deviance', 'exponential']\n",
    "        'n_estimators': Integer(50, 100),\n",
    "        'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "        'max_depth': Integer(1, 50),\n",
    "        'max_features' : Categorical(['sqrt', 'log2']),\n",
    "        'min_samples_split' : Integer(2, 10),\n",
    "        'min_samples_leaf' : Integer(1, 5),\n",
    "        'criterion' : Categorical(['friedman_mse', 'mae']),\n",
    "        'subsample' : Real(0.5, 1.0, 'uniform')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0c17202",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_params = dict()\n",
    "\n",
    "tuning_params['RF'] = {\n",
    "        'n_estimators': Integer(50, 200),\n",
    "        'max_depth': Integer(1, 50),\n",
    "        'max_features' : Categorical(['sqrt', 'log2']),\n",
    "        'min_samples_split' : Integer(2, 10),\n",
    "        'min_samples_leaf' : Integer(1, 5),\n",
    "        'criterion' : Categorical(['gini', 'entropy']),\n",
    "        'bootstrap' : Categorical([True, False]),\n",
    "        'max_samples' : Real(0.5, 0.99, 'uniform'),\n",
    "        #'warm_start' : Categorical([True, False]),  \n",
    "        #'ccp_alpha' : Real(1e-9, 1.0, 'log-uniform')\n",
    "}\n",
    "\n",
    "tuning_params['ExRF'] = {\n",
    "        'n_estimators': Integer(50, 200),\n",
    "        'max_depth': Integer(1, 50),\n",
    "        'max_features' : Categorical(['sqrt', 'log2']),\n",
    "        'min_samples_split' : Integer(2, 10),\n",
    "        'min_samples_leaf' : Integer(1, 5),\n",
    "        'criterion' : Categorical(['gini', 'entropy']),\n",
    "        'bootstrap' : Categorical([True, False]),\n",
    "        'max_samples' : Real(0.5, 0.99, 'uniform'),\n",
    "        #'warm_start' : Categorical([True, False]),        \n",
    "        #'ccp_alpha' : Real(1e-9, 1.0, 'log-uniform')\n",
    "}\n",
    "\n",
    "tuning_params['AdaBoost'] = {\n",
    "        'base_estimator' : Categorical([DecisionTreeClassifier(max_depth=2)]),\n",
    "        'n_estimators': Integer(50, 500),\n",
    "        'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "        'algorithm' : Categorical(['SAMME', 'SAMME.R'])\n",
    "}\n",
    "\n",
    "tuning_params['XGBoost'] = {\n",
    "        'n_estimators': Integer(50, 100),\n",
    "        'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "        'min_child_weight': Integer(0, 10),\n",
    "        'max_depth': Integer(1, 20), #(0,50)\n",
    "        'gamma': Real(1e-9, 0.5, 'log-uniform'),\n",
    "        'subsample': Real(0.5, 1.0, 'uniform'), #(0.01, 1.0, 'uniform')                      \n",
    "        'colsample_bytree': Real(0.1, 1.0, 'uniform'), #Real(0.01, 1.0, 'uniform')        \n",
    "        'lambda': Real(1e-9, 1000, 'log-uniform'),\n",
    "        'alpha': Real(1e-9, 1.0, 'log-uniform'),\n",
    "        #'colsample_bylevel': Real(0.1, 1.0, 'uniform'), #Real(0.01, 1.0, 'uniform')\n",
    "        #'max_delta_step': Integer(0, 10),  \n",
    "        #'scale_pos_weight': Real(1e-6, 500, 'log-uniform')\n",
    "}\n",
    "\n",
    "tuning_params['LightGBM'] = {\n",
    "        'n_estimators': Integer(50, 100),\n",
    "        'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "        'min_child_weight': Integer(0, 10),\n",
    "        'num_leaves': Integer(1, 100),      \n",
    "        'max_depth': Integer(1, 50),\n",
    "        'min_child_samples': Integer(0, 50),\n",
    "        'subsample': Real(0.5, 1.0, 'uniform'),\n",
    "        'colsample_bytree': Real(0.1, 1.0, 'uniform'),\n",
    "        'lambda': Real(1e-9, 1000, 'log-uniform'),\n",
    "        'alpha': Real(1e-9, 1.0, 'log-uniform'),\n",
    "        #'max_bin': Integer(100, 1000),\n",
    "        #'subsample_freq': Integer(0, 10),\n",
    "        #'subsample_for_bin': Integer(100000, 500000),\n",
    "        #'scale_pos_weight': Real(1e-6, 500, 'log-uniform')\n",
    "}\n",
    "    \n",
    "tuning_params['CatBoost'] = {\n",
    "        'iterations': Integer(10, 1000),\n",
    "        'depth': Integer(1, 10),\n",
    "        'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "        'random_strength': Real(1e-9, 10, 'log-uniform'),\n",
    "        'bagging_temperature': Real(0.0, 1.0, 'uniform'),\n",
    "        'l2_leaf_reg': Integer(2, 30),\n",
    "        'grow_policy' : Categorical(['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "        #'border_count': Integer(1, 255),       \n",
    "        #'scale_pos_weight':Real(0.01, 1.0, 'uniform')}\n",
    "}\n",
    "\n",
    "\n",
    "cv_strategy = StratifiedKFold( n_splits=5, shuffle=True, random_state=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1ca84de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(X_train, y_train, model, tuning_params, scoring='accuracy', cv_strategy=None, n_settings = 25, verbose=True, file_prefix='', best_model=False):\n",
    "\n",
    "    bsearch = BayesSearchCV(estimator = model,\n",
    "                            search_spaces = tuning_params,                        \n",
    "                            scoring = scoring,\n",
    "                            cv = cv_strategy,\n",
    "                            n_jobs = -1,\n",
    "                            verbose = 0,\n",
    "                            random_state = 1,\n",
    "                            n_iter = n_settings)\n",
    "    \n",
    "    \n",
    "    def status_print(optim_result):\n",
    "        \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
    "\n",
    "        # Get all the models tested so far in DataFrame format\n",
    "        all_models = pd.DataFrame(bsearch.cv_results_)    \n",
    "\n",
    "        # Get current parameters and the best parameters    \n",
    "        best_params = pd.Series(bsearch.best_params_)\n",
    "        if verbose == True:\n",
    "                print('Model #{}\\nBest {}: {}\\nBest params: {}\\n'.format(\n",
    "                len(all_models),\n",
    "                scoring.upper(),\n",
    "                np.round(bsearch.best_score_, 4),\n",
    "                bsearch.best_params_\n",
    "                ))\n",
    "\n",
    "        # Save all model results\n",
    "        clf_name = bsearch.estimator.__class__.__name__\n",
    "        all_models.to_csv(os.path.join(\"bayes-search-models\", file_prefix+'_'+clf_name+\"_cv_results.csv\"))\n",
    "\n",
    "        \n",
    "    bsearch.fit(X_train,y_train, callback=status_print)\n",
    "\n",
    "    result = bsearch.best_params_\n",
    "    \n",
    "    if best_model == True:\n",
    "        result = bsearch.best_params_, bsearch.best_estimator_\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be570492",
   "metadata": {},
   "source": [
    "**Testing RF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbb765ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1\n",
      "Best ACCURACY: 0.9109\n",
      "Best params: OrderedDict([('bootstrap', True), ('criterion', 'entropy'), ('max_depth', 19), ('max_features', 'log2'), ('max_samples', 0.7416559821292414), ('min_samples_leaf', 5), ('min_samples_split', 2), ('n_estimators', 88)])\n",
      "\n",
      "Model #2\n",
      "Best ACCURACY: 0.9109\n",
      "Best params: OrderedDict([('bootstrap', True), ('criterion', 'entropy'), ('max_depth', 19), ('max_features', 'log2'), ('max_samples', 0.7416559821292414), ('min_samples_leaf', 5), ('min_samples_split', 2), ('n_estimators', 88)])\n",
      "\n",
      "Model #3\n",
      "Best ACCURACY: 0.9115\n",
      "Best params: OrderedDict([('bootstrap', True), ('criterion', 'entropy'), ('max_depth', 39), ('max_features', 'log2'), ('max_samples', 0.7194966829176728), ('min_samples_leaf', 4), ('min_samples_split', 7), ('n_estimators', 103)])\n",
      "\n",
      "Model #4\n",
      "Best ACCURACY: 0.9115\n",
      "Best params: OrderedDict([('bootstrap', True), ('criterion', 'entropy'), ('max_depth', 39), ('max_features', 'log2'), ('max_samples', 0.7194966829176728), ('min_samples_leaf', 4), ('min_samples_split', 7), ('n_estimators', 103)])\n",
      "\n",
      "Model #5\n",
      "Best ACCURACY: 0.9115\n",
      "Best params: OrderedDict([('bootstrap', True), ('criterion', 'entropy'), ('max_depth', 39), ('max_features', 'log2'), ('max_samples', 0.7194966829176728), ('min_samples_leaf', 4), ('min_samples_split', 7), ('n_estimators', 103)])\n",
      "\n",
      "Model #6\n",
      "Best ACCURACY: 0.9396\n",
      "Best params: OrderedDict([('bootstrap', True), ('criterion', 'entropy'), ('max_depth', 30), ('max_features', 'log2'), ('max_samples', 0.8074655102407171), ('min_samples_leaf', 1), ('min_samples_split', 7), ('n_estimators', 96)])\n",
      "\n",
      "Model #7\n",
      "Best ACCURACY: 0.9396\n",
      "Best params: OrderedDict([('bootstrap', True), ('criterion', 'entropy'), ('max_depth', 30), ('max_features', 'log2'), ('max_samples', 0.8074655102407171), ('min_samples_leaf', 1), ('min_samples_split', 7), ('n_estimators', 96)])\n",
      "\n",
      "Model #8\n",
      "Best ACCURACY: 0.942\n",
      "Best params: OrderedDict([('bootstrap', False), ('criterion', 'gini'), ('max_depth', 41), ('max_features', 'sqrt'), ('max_samples', 0.8117255219265136), ('min_samples_leaf', 1), ('min_samples_split', 6), ('n_estimators', 51)])\n",
      "\n",
      "Model #9\n",
      "Best ACCURACY: 0.942\n",
      "Best params: OrderedDict([('bootstrap', False), ('criterion', 'gini'), ('max_depth', 41), ('max_features', 'sqrt'), ('max_samples', 0.8117255219265136), ('min_samples_leaf', 1), ('min_samples_split', 6), ('n_estimators', 51)])\n",
      "\n",
      "Model #10\n",
      "Best ACCURACY: 0.942\n",
      "Best params: OrderedDict([('bootstrap', False), ('criterion', 'gini'), ('max_depth', 41), ('max_features', 'sqrt'), ('max_samples', 0.8117255219265136), ('min_samples_leaf', 1), ('min_samples_split', 6), ('n_estimators', 51)])\n",
      "\n",
      "Model #11\n",
      "Best ACCURACY: 0.942\n",
      "Best params: OrderedDict([('bootstrap', False), ('criterion', 'gini'), ('max_depth', 41), ('max_features', 'sqrt'), ('max_samples', 0.8117255219265136), ('min_samples_leaf', 1), ('min_samples_split', 6), ('n_estimators', 51)])\n",
      "\n",
      "Model #12\n",
      "Best ACCURACY: 0.942\n",
      "Best params: OrderedDict([('bootstrap', False), ('criterion', 'gini'), ('max_depth', 41), ('max_features', 'sqrt'), ('max_samples', 0.8117255219265136), ('min_samples_leaf', 1), ('min_samples_split', 6), ('n_estimators', 51)])\n",
      "\n",
      "Model #13\n",
      "Best ACCURACY: 0.9439\n",
      "Best params: OrderedDict([('bootstrap', True), ('criterion', 'entropy'), ('max_depth', 50), ('max_features', 'log2'), ('max_samples', 0.99), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 50)])\n",
      "\n",
      "Model #14\n",
      "Best ACCURACY: 0.9471\n",
      "Best params: OrderedDict([('bootstrap', False), ('criterion', 'gini'), ('max_depth', 33), ('max_features', 'sqrt'), ('max_samples', 0.99), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 200)])\n",
      "\n",
      "Model #15\n",
      "Best ACCURACY: 0.9471\n",
      "Best params: OrderedDict([('bootstrap', False), ('criterion', 'gini'), ('max_depth', 33), ('max_features', 'sqrt'), ('max_samples', 0.99), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 200)])\n",
      "\n",
      "Model #16\n",
      "Best ACCURACY: 0.9471\n",
      "Best params: OrderedDict([('bootstrap', False), ('criterion', 'gini'), ('max_depth', 33), ('max_features', 'sqrt'), ('max_samples', 0.99), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 200)])\n",
      "\n",
      "Model #17\n",
      "Best ACCURACY: 0.9471\n",
      "Best params: OrderedDict([('bootstrap', False), ('criterion', 'gini'), ('max_depth', 33), ('max_features', 'sqrt'), ('max_samples', 0.99), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 200)])\n",
      "\n",
      "Model #18\n",
      "Best ACCURACY: 0.9471\n",
      "Best params: OrderedDict([('bootstrap', False), ('criterion', 'gini'), ('max_depth', 33), ('max_features', 'sqrt'), ('max_samples', 0.99), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 200)])\n",
      "\n",
      "Model #19\n",
      "Best ACCURACY: 0.9471\n",
      "Best params: OrderedDict([('bootstrap', False), ('criterion', 'gini'), ('max_depth', 33), ('max_features', 'sqrt'), ('max_samples', 0.99), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 200)])\n",
      "\n",
      "Model #20\n",
      "Best ACCURACY: 0.9471\n",
      "Best params: OrderedDict([('bootstrap', False), ('criterion', 'gini'), ('max_depth', 33), ('max_features', 'sqrt'), ('max_samples', 0.99), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 200)])\n",
      "\n",
      "Model #21\n",
      "Best ACCURACY: 0.9471\n",
      "Best params: OrderedDict([('bootstrap', False), ('criterion', 'gini'), ('max_depth', 33), ('max_features', 'sqrt'), ('max_samples', 0.99), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 200)])\n",
      "\n",
      "Model #22\n",
      "Best ACCURACY: 0.9471\n",
      "Best params: OrderedDict([('bootstrap', False), ('criterion', 'gini'), ('max_depth', 33), ('max_features', 'sqrt'), ('max_samples', 0.99), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 200)])\n",
      "\n",
      "Model #23\n",
      "Best ACCURACY: 0.9471\n",
      "Best params: OrderedDict([('bootstrap', False), ('criterion', 'gini'), ('max_depth', 33), ('max_features', 'sqrt'), ('max_samples', 0.99), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 200)])\n",
      "\n",
      "Model #24\n",
      "Best ACCURACY: 0.9471\n",
      "Best params: OrderedDict([('bootstrap', False), ('criterion', 'gini'), ('max_depth', 33), ('max_features', 'sqrt'), ('max_samples', 0.99), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 200)])\n",
      "\n",
      "Model #25\n",
      "Best ACCURACY: 0.9471\n",
      "Best params: OrderedDict([('bootstrap', False), ('criterion', 'gini'), ('max_depth', 33), ('max_features', 'sqrt'), ('max_samples', 0.99), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 200)])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EXECUTION TIME : hyperparameter_tuning ran in 94.41s\n"
     ]
    }
   ],
   "source": [
    "X, y = create_X_y_(oh_apis)\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "rf_best_params = hyperparameter_tuning(X, y, \n",
    "                                       model = rf_model, \n",
    "                                       tuning_params = tuning_params['RF'],\n",
    "                                       scoring = 'accuracy',\n",
    "                                       cv_strategy = cv_strategy,\n",
    "                                       n_settings = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de1da474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EXECUTION TIME : score_model_dataset ran in 17.27s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.9480644599958615 ( +/- 0.010331328795484306 )\n"
     ]
    }
   ],
   "source": [
    "api_scores_ = score_model_dataset(oh_apis, RandomForestClassifier(**rf_best_params))\n",
    "print(f' {np.mean(api_scores_)} ( +/- {np.std(api_scores_)} )')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccedd7fb",
   "metadata": {},
   "source": [
    "**Testing ExRF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8edb580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1\n",
      "Best ACCURACY: 0.8899\n",
      "Best params: OrderedDict([('bootstrap', True), ('ccp_alpha', 3.5881086588351177e-09), ('criterion', 'entropy'), ('max_depth', 8), ('max_features', 'log2'), ('max_samples', 0.9355734484361333), ('min_samples_leaf', 1), ('min_samples_split', 4), ('n_estimators', 122), ('warm_start', True)])\n",
      "\n",
      "Model #2\n",
      "Best ACCURACY: 0.9378\n",
      "Best params: OrderedDict([('bootstrap', True), ('ccp_alpha', 1.0267362767027556e-06), ('criterion', 'entropy'), ('max_depth', 22), ('max_features', 'log2'), ('max_samples', 0.8657545635146762), ('min_samples_leaf', 1), ('min_samples_split', 5), ('n_estimators', 179), ('warm_start', True)])\n",
      "\n",
      "Model #3\n",
      "Best ACCURACY: 0.9378\n",
      "Best params: OrderedDict([('bootstrap', True), ('ccp_alpha', 1.0267362767027556e-06), ('criterion', 'entropy'), ('max_depth', 22), ('max_features', 'log2'), ('max_samples', 0.8657545635146762), ('min_samples_leaf', 1), ('min_samples_split', 5), ('n_estimators', 179), ('warm_start', True)])\n",
      "\n",
      "Model #4\n",
      "Best ACCURACY: 0.9378\n",
      "Best params: OrderedDict([('bootstrap', True), ('ccp_alpha', 1.0267362767027556e-06), ('criterion', 'entropy'), ('max_depth', 22), ('max_features', 'log2'), ('max_samples', 0.8657545635146762), ('min_samples_leaf', 1), ('min_samples_split', 5), ('n_estimators', 179), ('warm_start', True)])\n",
      "\n",
      "Model #5\n",
      "Best ACCURACY: 0.9378\n",
      "Best params: OrderedDict([('bootstrap', True), ('ccp_alpha', 1.0267362767027556e-06), ('criterion', 'entropy'), ('max_depth', 22), ('max_features', 'log2'), ('max_samples', 0.8657545635146762), ('min_samples_leaf', 1), ('min_samples_split', 5), ('n_estimators', 179), ('warm_start', True)])\n",
      "\n",
      "Model #6\n",
      "Best ACCURACY: 0.9378\n",
      "Best params: OrderedDict([('bootstrap', True), ('ccp_alpha', 1.0267362767027556e-06), ('criterion', 'entropy'), ('max_depth', 22), ('max_features', 'log2'), ('max_samples', 0.8657545635146762), ('min_samples_leaf', 1), ('min_samples_split', 5), ('n_estimators', 179), ('warm_start', True)])\n",
      "\n",
      "Model #7\n",
      "Best ACCURACY: 0.9378\n",
      "Best params: OrderedDict([('bootstrap', True), ('ccp_alpha', 1.0267362767027556e-06), ('criterion', 'entropy'), ('max_depth', 22), ('max_features', 'log2'), ('max_samples', 0.8657545635146762), ('min_samples_leaf', 1), ('min_samples_split', 5), ('n_estimators', 179), ('warm_start', True)])\n",
      "\n",
      "Model #8\n",
      "Best ACCURACY: 0.9378\n",
      "Best params: OrderedDict([('bootstrap', True), ('ccp_alpha', 1.0267362767027556e-06), ('criterion', 'entropy'), ('max_depth', 22), ('max_features', 'log2'), ('max_samples', 0.8657545635146762), ('min_samples_leaf', 1), ('min_samples_split', 5), ('n_estimators', 179), ('warm_start', True)])\n",
      "\n",
      "Model #9\n",
      "Best ACCURACY: 0.9378\n",
      "Best params: OrderedDict([('bootstrap', True), ('ccp_alpha', 1.0267362767027556e-06), ('criterion', 'entropy'), ('max_depth', 22), ('max_features', 'log2'), ('max_samples', 0.8657545635146762), ('min_samples_leaf', 1), ('min_samples_split', 5), ('n_estimators', 179), ('warm_start', True)])\n",
      "\n",
      "Model #10\n",
      "Best ACCURACY: 0.9378\n",
      "Best params: OrderedDict([('bootstrap', True), ('ccp_alpha', 1.0267362767027556e-06), ('criterion', 'entropy'), ('max_depth', 22), ('max_features', 'log2'), ('max_samples', 0.8657545635146762), ('min_samples_leaf', 1), ('min_samples_split', 5), ('n_estimators', 179), ('warm_start', True)])\n",
      "\n",
      "Model #11\n",
      "Best ACCURACY: 0.9378\n",
      "Best params: OrderedDict([('bootstrap', True), ('ccp_alpha', 1.0267362767027556e-06), ('criterion', 'entropy'), ('max_depth', 22), ('max_features', 'log2'), ('max_samples', 0.8657545635146762), ('min_samples_leaf', 1), ('min_samples_split', 5), ('n_estimators', 179), ('warm_start', True)])\n",
      "\n",
      "Model #12\n",
      "Best ACCURACY: 0.9378\n",
      "Best params: OrderedDict([('bootstrap', True), ('ccp_alpha', 1.0267362767027556e-06), ('criterion', 'entropy'), ('max_depth', 22), ('max_features', 'log2'), ('max_samples', 0.8657545635146762), ('min_samples_leaf', 1), ('min_samples_split', 5), ('n_estimators', 179), ('warm_start', True)])\n",
      "\n",
      "Model #13\n",
      "Best ACCURACY: 0.9378\n",
      "Best params: OrderedDict([('bootstrap', True), ('ccp_alpha', 1.0267362767027556e-06), ('criterion', 'entropy'), ('max_depth', 22), ('max_features', 'log2'), ('max_samples', 0.8657545635146762), ('min_samples_leaf', 1), ('min_samples_split', 5), ('n_estimators', 179), ('warm_start', True)])\n",
      "\n",
      "Model #14\n",
      "Best ACCURACY: 0.9378\n",
      "Best params: OrderedDict([('bootstrap', True), ('ccp_alpha', 1.0267362767027556e-06), ('criterion', 'entropy'), ('max_depth', 22), ('max_features', 'log2'), ('max_samples', 0.8657545635146762), ('min_samples_leaf', 1), ('min_samples_split', 5), ('n_estimators', 179), ('warm_start', True)])\n",
      "\n",
      "Model #15\n",
      "Best ACCURACY: 0.942\n",
      "Best params: OrderedDict([('bootstrap', False), ('ccp_alpha', 2.6951192424369455e-08), ('criterion', 'gini'), ('max_depth', 37), ('max_features', 'log2'), ('max_samples', 0.5579300926009148), ('min_samples_leaf', 1), ('min_samples_split', 10), ('n_estimators', 159), ('warm_start', False)])\n",
      "\n",
      "Model #16\n",
      "Best ACCURACY: 0.942\n",
      "Best params: OrderedDict([('bootstrap', False), ('ccp_alpha', 2.6951192424369455e-08), ('criterion', 'gini'), ('max_depth', 37), ('max_features', 'log2'), ('max_samples', 0.5579300926009148), ('min_samples_leaf', 1), ('min_samples_split', 10), ('n_estimators', 159), ('warm_start', False)])\n",
      "\n",
      "Model #17\n",
      "Best ACCURACY: 0.942\n",
      "Best params: OrderedDict([('bootstrap', False), ('ccp_alpha', 2.6951192424369455e-08), ('criterion', 'gini'), ('max_depth', 37), ('max_features', 'log2'), ('max_samples', 0.5579300926009148), ('min_samples_leaf', 1), ('min_samples_split', 10), ('n_estimators', 159), ('warm_start', False)])\n",
      "\n",
      "Model #18\n",
      "Best ACCURACY: 0.942\n",
      "Best params: OrderedDict([('bootstrap', False), ('ccp_alpha', 2.6951192424369455e-08), ('criterion', 'gini'), ('max_depth', 37), ('max_features', 'log2'), ('max_samples', 0.5579300926009148), ('min_samples_leaf', 1), ('min_samples_split', 10), ('n_estimators', 159), ('warm_start', False)])\n",
      "\n",
      "Model #19\n",
      "Best ACCURACY: 0.942\n",
      "Best params: OrderedDict([('bootstrap', False), ('ccp_alpha', 2.6951192424369455e-08), ('criterion', 'gini'), ('max_depth', 37), ('max_features', 'log2'), ('max_samples', 0.5579300926009148), ('min_samples_leaf', 1), ('min_samples_split', 10), ('n_estimators', 159), ('warm_start', False)])\n",
      "\n",
      "Model #20\n",
      "Best ACCURACY: 0.942\n",
      "Best params: OrderedDict([('bootstrap', False), ('ccp_alpha', 2.6951192424369455e-08), ('criterion', 'gini'), ('max_depth', 37), ('max_features', 'log2'), ('max_samples', 0.5579300926009148), ('min_samples_leaf', 1), ('min_samples_split', 10), ('n_estimators', 159), ('warm_start', False)])\n",
      "\n",
      "Model #21\n",
      "Best ACCURACY: 0.942\n",
      "Best params: OrderedDict([('bootstrap', False), ('ccp_alpha', 2.6951192424369455e-08), ('criterion', 'gini'), ('max_depth', 37), ('max_features', 'log2'), ('max_samples', 0.5579300926009148), ('min_samples_leaf', 1), ('min_samples_split', 10), ('n_estimators', 159), ('warm_start', False)])\n",
      "\n",
      "Model #22\n",
      "Best ACCURACY: 0.942\n",
      "Best params: OrderedDict([('bootstrap', False), ('ccp_alpha', 2.6951192424369455e-08), ('criterion', 'gini'), ('max_depth', 37), ('max_features', 'log2'), ('max_samples', 0.5579300926009148), ('min_samples_leaf', 1), ('min_samples_split', 10), ('n_estimators', 159), ('warm_start', False)])\n",
      "\n",
      "Model #23\n",
      "Best ACCURACY: 0.942\n",
      "Best params: OrderedDict([('bootstrap', False), ('ccp_alpha', 2.6951192424369455e-08), ('criterion', 'gini'), ('max_depth', 37), ('max_features', 'log2'), ('max_samples', 0.5579300926009148), ('min_samples_leaf', 1), ('min_samples_split', 10), ('n_estimators', 159), ('warm_start', False)])\n",
      "\n",
      "Model #24\n",
      "Best ACCURACY: 0.942\n",
      "Best params: OrderedDict([('bootstrap', False), ('ccp_alpha', 2.6951192424369455e-08), ('criterion', 'gini'), ('max_depth', 37), ('max_features', 'log2'), ('max_samples', 0.5579300926009148), ('min_samples_leaf', 1), ('min_samples_split', 10), ('n_estimators', 159), ('warm_start', False)])\n",
      "\n",
      "Model #25\n",
      "Best ACCURACY: 0.942\n",
      "Best params: OrderedDict([('bootstrap', False), ('ccp_alpha', 2.6951192424369455e-08), ('criterion', 'gini'), ('max_depth', 37), ('max_features', 'log2'), ('max_samples', 0.5579300926009148), ('min_samples_leaf', 1), ('min_samples_split', 10), ('n_estimators', 159), ('warm_start', False)])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EXECUTION TIME : hyperparameter_tuning ran in 99.11s\n"
     ]
    }
   ],
   "source": [
    "X, y = create_X_y_(oh_apis)\n",
    "\n",
    "ex_model = ExtraTreesClassifier()\n",
    "\n",
    "ex_best_params = hyperparameter_tuning(X, y, \n",
    "                                       model = ex_model, \n",
    "                                       tuning_params = tuning_params['ExRF'],\n",
    "                                       scoring = 'accuracy',\n",
    "                                       cv_strategy = cv_strategy,\n",
    "                                       n_settings = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4048ff9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EXECUTION TIME : score_model_dataset ran in 8.94s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.9444297082228115 ( +/- 0.01088449203327669 )\n"
     ]
    }
   ],
   "source": [
    "api_scores_ = score_model_dataset(oh_apis, ExtraTreesClassifier(**ex_best_params))\n",
    "print(f' {np.mean(api_scores_)} ( +/- {np.std(api_scores_)} )')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8d3616",
   "metadata": {},
   "source": [
    "**Testing GradientBoostingClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b0483ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1\n",
      "Best ACCURACY: 0.8785\n",
      "Best params: OrderedDict([('criterion', 'mae'), ('learning_rate', 0.01328322299832468), ('loss', 'deviance'), ('max_depth', 8), ('max_features', 'log2'), ('min_samples_leaf', 5), ('min_samples_split', 2), ('n_estimators', 63), ('subsample', 0.7394782887996654)])\n",
      "\n",
      "Model #2\n",
      "Best ACCURACY: 0.9295\n",
      "Best params: OrderedDict([('criterion', 'mae'), ('learning_rate', 0.04668884070205238), ('loss', 'deviance'), ('max_depth', 22), ('max_features', 'log2'), ('min_samples_leaf', 4), ('min_samples_split', 2), ('n_estimators', 68), ('subsample', 0.928723943060398)])\n",
      "\n",
      "Model #3\n",
      "Best ACCURACY: 0.9295\n",
      "Best params: OrderedDict([('criterion', 'mae'), ('learning_rate', 0.04668884070205238), ('loss', 'deviance'), ('max_depth', 22), ('max_features', 'log2'), ('min_samples_leaf', 4), ('min_samples_split', 2), ('n_estimators', 68), ('subsample', 0.928723943060398)])\n",
      "\n",
      "Model #4\n",
      "Best ACCURACY: 0.9357\n",
      "Best params: OrderedDict([('criterion', 'mae'), ('learning_rate', 0.06654968297130963), ('loss', 'deviance'), ('max_depth', 21), ('max_features', 'log2'), ('min_samples_leaf', 4), ('min_samples_split', 10), ('n_estimators', 81), ('subsample', 0.7635782745932461)])\n",
      "\n",
      "Model #5\n",
      "Best ACCURACY: 0.9394\n",
      "Best params: OrderedDict([('criterion', 'mae'), ('learning_rate', 0.05236293929735302), ('loss', 'deviance'), ('max_depth', 29), ('max_features', 'log2'), ('min_samples_leaf', 3), ('min_samples_split', 8), ('n_estimators', 75), ('subsample', 0.9382689022901303)])\n",
      "\n",
      "Model #6\n",
      "Best ACCURACY: 0.9394\n",
      "Best params: OrderedDict([('criterion', 'mae'), ('learning_rate', 0.05236293929735302), ('loss', 'deviance'), ('max_depth', 29), ('max_features', 'log2'), ('min_samples_leaf', 3), ('min_samples_split', 8), ('n_estimators', 75), ('subsample', 0.9382689022901303)])\n",
      "\n",
      "Model #7\n",
      "Best ACCURACY: 0.9394\n",
      "Best params: OrderedDict([('criterion', 'mae'), ('learning_rate', 0.05236293929735302), ('loss', 'deviance'), ('max_depth', 29), ('max_features', 'log2'), ('min_samples_leaf', 3), ('min_samples_split', 8), ('n_estimators', 75), ('subsample', 0.9382689022901303)])\n",
      "\n",
      "Model #8\n",
      "Best ACCURACY: 0.942\n",
      "Best params: OrderedDict([('criterion', 'friedman_mse'), ('learning_rate', 0.30044074314959107), ('loss', 'exponential'), ('max_depth', 28), ('max_features', 'sqrt'), ('min_samples_leaf', 1), ('min_samples_split', 6), ('n_estimators', 50), ('subsample', 0.5657522887795485)])\n",
      "\n",
      "Model #9\n",
      "Best ACCURACY: 0.946\n",
      "Best params: OrderedDict([('criterion', 'friedman_mse'), ('learning_rate', 0.10891896379362535), ('loss', 'exponential'), ('max_depth', 34), ('max_features', 'log2'), ('min_samples_leaf', 3), ('min_samples_split', 5), ('n_estimators', 96), ('subsample', 0.6665270013623132)])\n",
      "\n",
      "Model #10\n",
      "Best ACCURACY: 0.946\n",
      "Best params: OrderedDict([('criterion', 'friedman_mse'), ('learning_rate', 0.10891896379362535), ('loss', 'exponential'), ('max_depth', 34), ('max_features', 'log2'), ('min_samples_leaf', 3), ('min_samples_split', 5), ('n_estimators', 96), ('subsample', 0.6665270013623132)])\n",
      "\n",
      "Model #11\n",
      "Best ACCURACY: 0.946\n",
      "Best params: OrderedDict([('criterion', 'friedman_mse'), ('learning_rate', 0.10891896379362535), ('loss', 'exponential'), ('max_depth', 34), ('max_features', 'log2'), ('min_samples_leaf', 3), ('min_samples_split', 5), ('n_estimators', 96), ('subsample', 0.6665270013623132)])\n",
      "\n",
      "Model #12\n",
      "Best ACCURACY: 0.946\n",
      "Best params: OrderedDict([('criterion', 'friedman_mse'), ('learning_rate', 0.10891896379362535), ('loss', 'exponential'), ('max_depth', 34), ('max_features', 'log2'), ('min_samples_leaf', 3), ('min_samples_split', 5), ('n_estimators', 96), ('subsample', 0.6665270013623132)])\n",
      "\n",
      "Model #13\n",
      "Best ACCURACY: 0.946\n",
      "Best params: OrderedDict([('criterion', 'friedman_mse'), ('learning_rate', 0.10891896379362535), ('loss', 'exponential'), ('max_depth', 34), ('max_features', 'log2'), ('min_samples_leaf', 3), ('min_samples_split', 5), ('n_estimators', 96), ('subsample', 0.6665270013623132)])\n",
      "\n",
      "Model #14\n",
      "Best ACCURACY: 0.946\n",
      "Best params: OrderedDict([('criterion', 'friedman_mse'), ('learning_rate', 0.10891896379362535), ('loss', 'exponential'), ('max_depth', 34), ('max_features', 'log2'), ('min_samples_leaf', 3), ('min_samples_split', 5), ('n_estimators', 96), ('subsample', 0.6665270013623132)])\n",
      "\n",
      "Model #15\n",
      "Best ACCURACY: 0.946\n",
      "Best params: OrderedDict([('criterion', 'friedman_mse'), ('learning_rate', 0.10891896379362535), ('loss', 'exponential'), ('max_depth', 34), ('max_features', 'log2'), ('min_samples_leaf', 3), ('min_samples_split', 5), ('n_estimators', 96), ('subsample', 0.6665270013623132)])\n",
      "\n",
      "Model #16\n",
      "Best ACCURACY: 0.946\n",
      "Best params: OrderedDict([('criterion', 'friedman_mse'), ('learning_rate', 0.10891896379362535), ('loss', 'exponential'), ('max_depth', 34), ('max_features', 'log2'), ('min_samples_leaf', 3), ('min_samples_split', 5), ('n_estimators', 96), ('subsample', 0.6665270013623132)])\n",
      "\n",
      "Model #17\n",
      "Best ACCURACY: 0.946\n",
      "Best params: OrderedDict([('criterion', 'friedman_mse'), ('learning_rate', 0.10891896379362535), ('loss', 'exponential'), ('max_depth', 34), ('max_features', 'log2'), ('min_samples_leaf', 3), ('min_samples_split', 5), ('n_estimators', 96), ('subsample', 0.6665270013623132)])\n",
      "\n",
      "Model #18\n",
      "Best ACCURACY: 0.9474\n",
      "Best params: OrderedDict([('criterion', 'mae'), ('learning_rate', 0.8690133098756432), ('loss', 'deviance'), ('max_depth', 39), ('max_features', 'log2'), ('min_samples_leaf', 1), ('min_samples_split', 10), ('n_estimators', 100), ('subsample', 1.0)])\n",
      "\n",
      "Model #19\n",
      "Best ACCURACY: 0.9474\n",
      "Best params: OrderedDict([('criterion', 'mae'), ('learning_rate', 0.8690133098756432), ('loss', 'deviance'), ('max_depth', 39), ('max_features', 'log2'), ('min_samples_leaf', 1), ('min_samples_split', 10), ('n_estimators', 100), ('subsample', 1.0)])\n",
      "\n",
      "Model #20\n",
      "Best ACCURACY: 0.9474\n",
      "Best params: OrderedDict([('criterion', 'mae'), ('learning_rate', 0.8690133098756432), ('loss', 'deviance'), ('max_depth', 39), ('max_features', 'log2'), ('min_samples_leaf', 1), ('min_samples_split', 10), ('n_estimators', 100), ('subsample', 1.0)])\n",
      "\n",
      "Model #21\n",
      "Best ACCURACY: 0.9474\n",
      "Best params: OrderedDict([('criterion', 'mae'), ('learning_rate', 0.8690133098756432), ('loss', 'deviance'), ('max_depth', 39), ('max_features', 'log2'), ('min_samples_leaf', 1), ('min_samples_split', 10), ('n_estimators', 100), ('subsample', 1.0)])\n",
      "\n",
      "Model #22\n",
      "Best ACCURACY: 0.9474\n",
      "Best params: OrderedDict([('criterion', 'mae'), ('learning_rate', 0.8690133098756432), ('loss', 'deviance'), ('max_depth', 39), ('max_features', 'log2'), ('min_samples_leaf', 1), ('min_samples_split', 10), ('n_estimators', 100), ('subsample', 1.0)])\n",
      "\n",
      "Model #23\n",
      "Best ACCURACY: 0.9474\n",
      "Best params: OrderedDict([('criterion', 'mae'), ('learning_rate', 0.8690133098756432), ('loss', 'deviance'), ('max_depth', 39), ('max_features', 'log2'), ('min_samples_leaf', 1), ('min_samples_split', 10), ('n_estimators', 100), ('subsample', 1.0)])\n",
      "\n",
      "Model #24\n",
      "Best ACCURACY: 0.9474\n",
      "Best params: OrderedDict([('criterion', 'mae'), ('learning_rate', 0.8690133098756432), ('loss', 'deviance'), ('max_depth', 39), ('max_features', 'log2'), ('min_samples_leaf', 1), ('min_samples_split', 10), ('n_estimators', 100), ('subsample', 1.0)])\n",
      "\n",
      "Model #25\n",
      "Best ACCURACY: 0.9474\n",
      "Best params: OrderedDict([('criterion', 'mae'), ('learning_rate', 0.8690133098756432), ('loss', 'deviance'), ('max_depth', 39), ('max_features', 'log2'), ('min_samples_leaf', 1), ('min_samples_split', 10), ('n_estimators', 100), ('subsample', 1.0)])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EXECUTION TIME : hyperparameter_tuning ran in 1353.42s\n"
     ]
    }
   ],
   "source": [
    "X, y = create_X_y_(oh_apis)\n",
    "\n",
    "gb_model = GradientBoostingClassifier()\n",
    "\n",
    "gb_best_params = hyperparameter_tuning(X, y, \n",
    "                                       model = gb_model, \n",
    "                                       tuning_params = tuning_params['GB'],\n",
    "                                       scoring = 'accuracy',\n",
    "                                       cv_strategy = cv_strategy,\n",
    "                                       n_settings = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cc90a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "api_scores_ = score_model_dataset(oh_apis, GradientBoostingClassifier(**gb_best_params))\n",
    "print(f' {np.mean(api_scores_)} ( +/- {np.std(api_scores_)} )')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abe1d48",
   "metadata": {},
   "source": [
    "**Testing AdaBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9f5b0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1\n",
      "Best ACCURACY: 0.8897\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.05672620790508927), ('n_estimators', 116)])\n",
      "\n",
      "Model #2\n",
      "Best ACCURACY: 0.8897\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.05672620790508927), ('n_estimators', 116)])\n",
      "\n",
      "Model #3\n",
      "Best ACCURACY: 0.9295\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3465259624840772), ('n_estimators', 176)])\n",
      "\n",
      "Model #4\n",
      "Best ACCURACY: 0.9295\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3465259624840772), ('n_estimators', 176)])\n",
      "\n",
      "Model #5\n",
      "Best ACCURACY: 0.9295\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3465259624840772), ('n_estimators', 176)])\n",
      "\n",
      "Model #6\n",
      "Best ACCURACY: 0.9295\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3465259624840772), ('n_estimators', 176)])\n",
      "\n",
      "Model #7\n",
      "Best ACCURACY: 0.9295\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3465259624840772), ('n_estimators', 176)])\n",
      "\n",
      "Model #8\n",
      "Best ACCURACY: 0.9295\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3465259624840772), ('n_estimators', 176)])\n",
      "\n",
      "Model #9\n",
      "Best ACCURACY: 0.9295\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3465259624840772), ('n_estimators', 176)])\n",
      "\n",
      "Model #10\n",
      "Best ACCURACY: 0.9295\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3465259624840772), ('n_estimators', 176)])\n",
      "\n",
      "Model #11\n",
      "Best ACCURACY: 0.9359\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 1.0), ('n_estimators', 500)])\n",
      "\n",
      "Model #12\n",
      "Best ACCURACY: 0.9359\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 1.0), ('n_estimators', 500)])\n",
      "\n",
      "Model #13\n",
      "Best ACCURACY: 0.9407\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3389796114285923), ('n_estimators', 500)])\n",
      "\n",
      "Model #14\n",
      "Best ACCURACY: 0.9407\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3389796114285923), ('n_estimators', 500)])\n",
      "\n",
      "Model #15\n",
      "Best ACCURACY: 0.9407\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3389796114285923), ('n_estimators', 500)])\n",
      "\n",
      "Model #16\n",
      "Best ACCURACY: 0.9407\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3389796114285923), ('n_estimators', 500)])\n",
      "\n",
      "Model #17\n",
      "Best ACCURACY: 0.9407\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3389796114285923), ('n_estimators', 500)])\n",
      "\n",
      "Model #18\n",
      "Best ACCURACY: 0.9407\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3389796114285923), ('n_estimators', 500)])\n",
      "\n",
      "Model #19\n",
      "Best ACCURACY: 0.9407\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3389796114285923), ('n_estimators', 500)])\n",
      "\n",
      "Model #20\n",
      "Best ACCURACY: 0.9407\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3389796114285923), ('n_estimators', 500)])\n",
      "\n",
      "Model #21\n",
      "Best ACCURACY: 0.9407\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3389796114285923), ('n_estimators', 500)])\n",
      "\n",
      "Model #22\n",
      "Best ACCURACY: 0.9407\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3389796114285923), ('n_estimators', 500)])\n",
      "\n",
      "Model #23\n",
      "Best ACCURACY: 0.9407\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3389796114285923), ('n_estimators', 500)])\n",
      "\n",
      "Model #24\n",
      "Best ACCURACY: 0.9407\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3389796114285923), ('n_estimators', 500)])\n",
      "\n",
      "Model #25\n",
      "Best ACCURACY: 0.9407\n",
      "Best params: OrderedDict([('algorithm', 'SAMME.R'), ('base_estimator', DecisionTreeClassifier(max_depth=2)), ('learning_rate', 0.3389796114285923), ('n_estimators', 500)])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EXECUTION TIME : hyperparameter_tuning ran in 300.32s\n"
     ]
    }
   ],
   "source": [
    "X, y = create_X_y_(oh_apis)\n",
    "\n",
    "ada_model = AdaBoostClassifier()\n",
    "\n",
    "ada_best_params = hyperparameter_tuning(X, y, \n",
    "                                       model = ada_model, \n",
    "                                       tuning_params = tuning_params['AdaBoost'],\n",
    "                                       scoring = 'accuracy',\n",
    "                                       cv_strategy = cv_strategy,\n",
    "                                       n_settings = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83bdd733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EXECUTION TIME : score_model_dataset ran in 68.75s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.9366297006979327 ( +/- 0.01356393599292852 )\n"
     ]
    }
   ],
   "source": [
    "api_scores_ = score_model_dataset(oh_apis, AdaBoostClassifier(**ada_best_params))\n",
    "print(f' {np.mean(api_scores_)} ( +/- {np.std(api_scores_)} )')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787c2254",
   "metadata": {},
   "source": [
    "**Testing XGB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94af5c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1\n",
      "Best ACCURACY: 0.9373\n",
      "Best params: OrderedDict([('alpha', 0.002107681249770302), ('colsample_bytree', 0.15548655863280092), ('gamma', 1.8992018546362966e-06), ('lambda', 5.593977880531548e-08), ('learning_rate', 0.09690606246621411), ('max_depth', 18), ('min_child_weight', 1), ('n_estimators', 63), ('subsample', 0.7394782887996654)])\n",
      "\n",
      "Model #2\n",
      "Best ACCURACY: 0.9455\n",
      "Best params: OrderedDict([('alpha', 0.0014191129358860485), ('colsample_bytree', 0.4011458906809745), ('gamma', 1.8023871181327715e-09), ('lambda', 0.00016493015774619377), ('learning_rate', 0.06410712948858617), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 68), ('subsample', 0.928723943060398)])\n",
      "\n",
      "Model #3\n",
      "Best ACCURACY: 0.9455\n",
      "Best params: OrderedDict([('alpha', 0.0014191129358860485), ('colsample_bytree', 0.4011458906809745), ('gamma', 1.8023871181327715e-09), ('lambda', 0.00016493015774619377), ('learning_rate', 0.06410712948858617), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 68), ('subsample', 0.928723943060398)])\n",
      "\n",
      "Model #4\n",
      "Best ACCURACY: 0.9455\n",
      "Best params: OrderedDict([('alpha', 0.0014191129358860485), ('colsample_bytree', 0.4011458906809745), ('gamma', 1.8023871181327715e-09), ('lambda', 0.00016493015774619377), ('learning_rate', 0.06410712948858617), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 68), ('subsample', 0.928723943060398)])\n",
      "\n",
      "Model #5\n",
      "Best ACCURACY: 0.9455\n",
      "Best params: OrderedDict([('alpha', 0.0014191129358860485), ('colsample_bytree', 0.4011458906809745), ('gamma', 1.8023871181327715e-09), ('lambda', 0.00016493015774619377), ('learning_rate', 0.06410712948858617), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 68), ('subsample', 0.928723943060398)])\n",
      "\n",
      "Model #6\n",
      "Best ACCURACY: 0.9455\n",
      "Best params: OrderedDict([('alpha', 0.0014191129358860485), ('colsample_bytree', 0.4011458906809745), ('gamma', 1.8023871181327715e-09), ('lambda', 0.00016493015774619377), ('learning_rate', 0.06410712948858617), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 68), ('subsample', 0.928723943060398)])\n",
      "\n",
      "Model #7\n",
      "Best ACCURACY: 0.9455\n",
      "Best params: OrderedDict([('alpha', 0.0014191129358860485), ('colsample_bytree', 0.4011458906809745), ('gamma', 1.8023871181327715e-09), ('lambda', 0.00016493015774619377), ('learning_rate', 0.06410712948858617), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 68), ('subsample', 0.928723943060398)])\n",
      "\n",
      "Model #8\n",
      "Best ACCURACY: 0.9455\n",
      "Best params: OrderedDict([('alpha', 0.0014191129358860485), ('colsample_bytree', 0.4011458906809745), ('gamma', 1.8023871181327715e-09), ('lambda', 0.00016493015774619377), ('learning_rate', 0.06410712948858617), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 68), ('subsample', 0.928723943060398)])\n",
      "\n",
      "Model #9\n",
      "Best ACCURACY: 0.9455\n",
      "Best params: OrderedDict([('alpha', 0.0014191129358860485), ('colsample_bytree', 0.4011458906809745), ('gamma', 1.8023871181327715e-09), ('lambda', 0.00016493015774619377), ('learning_rate', 0.06410712948858617), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 68), ('subsample', 0.928723943060398)])\n",
      "\n",
      "Model #10\n",
      "Best ACCURACY: 0.9455\n",
      "Best params: OrderedDict([('alpha', 0.0014191129358860485), ('colsample_bytree', 0.4011458906809745), ('gamma', 1.8023871181327715e-09), ('lambda', 0.00016493015774619377), ('learning_rate', 0.06410712948858617), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 68), ('subsample', 0.928723943060398)])\n",
      "\n",
      "Model #11\n",
      "Best ACCURACY: 0.9455\n",
      "Best params: OrderedDict([('alpha', 0.0014191129358860485), ('colsample_bytree', 0.4011458906809745), ('gamma', 1.8023871181327715e-09), ('lambda', 0.00016493015774619377), ('learning_rate', 0.06410712948858617), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 68), ('subsample', 0.928723943060398)])\n",
      "\n",
      "Model #12\n",
      "Best ACCURACY: 0.9455\n",
      "Best params: OrderedDict([('alpha', 0.0014191129358860485), ('colsample_bytree', 0.4011458906809745), ('gamma', 1.8023871181327715e-09), ('lambda', 0.00016493015774619377), ('learning_rate', 0.06410712948858617), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 68), ('subsample', 0.928723943060398)])\n",
      "\n",
      "Model #13\n",
      "Best ACCURACY: 0.9455\n",
      "Best params: OrderedDict([('alpha', 0.0014191129358860485), ('colsample_bytree', 0.4011458906809745), ('gamma', 1.8023871181327715e-09), ('lambda', 0.00016493015774619377), ('learning_rate', 0.06410712948858617), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 68), ('subsample', 0.928723943060398)])\n",
      "\n",
      "Model #14\n",
      "Best ACCURACY: 0.9455\n",
      "Best params: OrderedDict([('alpha', 0.0014191129358860485), ('colsample_bytree', 0.4011458906809745), ('gamma', 1.8023871181327715e-09), ('lambda', 0.00016493015774619377), ('learning_rate', 0.06410712948858617), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 68), ('subsample', 0.928723943060398)])\n",
      "\n",
      "Model #15\n",
      "Best ACCURACY: 0.9455\n",
      "Best params: OrderedDict([('alpha', 0.0014191129358860485), ('colsample_bytree', 0.4011458906809745), ('gamma', 1.8023871181327715e-09), ('lambda', 0.00016493015774619377), ('learning_rate', 0.06410712948858617), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 68), ('subsample', 0.928723943060398)])\n",
      "\n",
      "Model #16\n",
      "Best ACCURACY: 0.9455\n",
      "Best params: OrderedDict([('alpha', 0.0014191129358860485), ('colsample_bytree', 0.4011458906809745), ('gamma', 1.8023871181327715e-09), ('lambda', 0.00016493015774619377), ('learning_rate', 0.06410712948858617), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 68), ('subsample', 0.928723943060398)])\n",
      "\n",
      "Model #17\n",
      "Best ACCURACY: 0.9455\n",
      "Best params: OrderedDict([('alpha', 0.0014191129358860485), ('colsample_bytree', 0.4011458906809745), ('gamma', 1.8023871181327715e-09), ('lambda', 0.00016493015774619377), ('learning_rate', 0.06410712948858617), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 68), ('subsample', 0.928723943060398)])\n",
      "\n",
      "Model #18\n",
      "Best ACCURACY: 0.9487\n",
      "Best params: OrderedDict([('alpha', 6.837949891344249e-05), ('colsample_bytree', 0.4120911740852755), ('gamma', 1e-09), ('lambda', 1.626501023119927e-06), ('learning_rate', 0.37992426783942546), ('max_depth', 14), ('min_child_weight', 0), ('n_estimators', 50), ('subsample', 0.887400519617906)])\n",
      "\n",
      "Model #19\n",
      "Best ACCURACY: 0.9487\n",
      "Best params: OrderedDict([('alpha', 6.837949891344249e-05), ('colsample_bytree', 0.4120911740852755), ('gamma', 1e-09), ('lambda', 1.626501023119927e-06), ('learning_rate', 0.37992426783942546), ('max_depth', 14), ('min_child_weight', 0), ('n_estimators', 50), ('subsample', 0.887400519617906)])\n",
      "\n",
      "Model #20\n",
      "Best ACCURACY: 0.9489\n",
      "Best params: OrderedDict([('alpha', 0.00019924519155244455), ('colsample_bytree', 0.32989933298568475), ('gamma', 1e-09), ('lambda', 1.0342642810019773e-09), ('learning_rate', 0.29762436795987596), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 50), ('subsample', 0.857340870632541)])\n",
      "\n",
      "Model #21\n",
      "Best ACCURACY: 0.9489\n",
      "Best params: OrderedDict([('alpha', 0.00019924519155244455), ('colsample_bytree', 0.32989933298568475), ('gamma', 1e-09), ('lambda', 1.0342642810019773e-09), ('learning_rate', 0.29762436795987596), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 50), ('subsample', 0.857340870632541)])\n",
      "\n",
      "Model #22\n",
      "Best ACCURACY: 0.9489\n",
      "Best params: OrderedDict([('alpha', 0.00019924519155244455), ('colsample_bytree', 0.32989933298568475), ('gamma', 1e-09), ('lambda', 1.0342642810019773e-09), ('learning_rate', 0.29762436795987596), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 50), ('subsample', 0.857340870632541)])\n",
      "\n",
      "Model #23\n",
      "Best ACCURACY: 0.9489\n",
      "Best params: OrderedDict([('alpha', 0.00019924519155244455), ('colsample_bytree', 0.32989933298568475), ('gamma', 1e-09), ('lambda', 1.0342642810019773e-09), ('learning_rate', 0.29762436795987596), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 50), ('subsample', 0.857340870632541)])\n",
      "\n",
      "Model #24\n",
      "Best ACCURACY: 0.9489\n",
      "Best params: OrderedDict([('alpha', 0.00019924519155244455), ('colsample_bytree', 0.32989933298568475), ('gamma', 1e-09), ('lambda', 1.0342642810019773e-09), ('learning_rate', 0.29762436795987596), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 50), ('subsample', 0.857340870632541)])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #25\n",
      "Best ACCURACY: 0.9489\n",
      "Best params: OrderedDict([('alpha', 0.00019924519155244455), ('colsample_bytree', 0.32989933298568475), ('gamma', 1e-09), ('lambda', 1.0342642810019773e-09), ('learning_rate', 0.29762436795987596), ('max_depth', 15), ('min_child_weight', 0), ('n_estimators', 50), ('subsample', 0.857340870632541)])\n",
      "\n",
      "[01:31:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EXECUTION TIME : hyperparameter_tuning ran in 230.05s\n"
     ]
    }
   ],
   "source": [
    "X, y = create_X_y_(oh_apis)\n",
    "\n",
    "xgb_model = XGBClassifier(objective = 'binary:logistic', eval_metric = 'error', silent=1, tree_method='approx')\n",
    "\n",
    "xgb_best_params = hyperparameter_tuning(X, y, \n",
    "                                        model = XGBClassifier(), \n",
    "                                        tuning_params = tuning_params['XGBoost'],\n",
    "                                        scoring = 'accuracy',\n",
    "                                        cv_strategy = cv_strategy,\n",
    "                                        n_settings = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92a104f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EXECUTION TIME : score_model_dataset ran in 33.11s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.9483283010704142 ( +/- 0.009336448192940898 )\n"
     ]
    }
   ],
   "source": [
    "api_scores_ = score_model_dataset(oh_apis, XGBClassifier(**xgb_best_params))\n",
    "print(f' {np.mean(api_scores_)} ( +/- {np.std(api_scores_)} )')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0987f5",
   "metadata": {},
   "source": [
    "**Testing LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "091915ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1\n",
      "Best ROC_AUC: 0.9722\n",
      "Best params: OrderedDict([('learning_rate', 0.2542669917403192), ('max_depth', 3), ('min_child_samples', 19), ('n_estimators', 57), ('num_leaves', 50)])\n",
      "\n",
      "Model #2\n",
      "Best ROC_AUC: 0.9837\n",
      "Best params: OrderedDict([('learning_rate', 0.2328707166744412), ('max_depth', 17), ('min_child_samples', 1), ('n_estimators', 72), ('num_leaves', 42)])\n",
      "\n",
      "Model #3\n",
      "Best ROC_AUC: 0.9837\n",
      "Best params: OrderedDict([('learning_rate', 0.2328707166744412), ('max_depth', 17), ('min_child_samples', 1), ('n_estimators', 72), ('num_leaves', 42)])\n",
      "\n",
      "Model #4\n",
      "Best ROC_AUC: 0.9837\n",
      "Best params: OrderedDict([('learning_rate', 0.2551996554556929), ('max_depth', 21), ('min_child_samples', 6), ('n_estimators', 70), ('num_leaves', 43)])\n",
      "\n",
      "Model #5\n",
      "Best ROC_AUC: 0.9837\n",
      "Best params: OrderedDict([('learning_rate', 0.2551996554556929), ('max_depth', 21), ('min_child_samples', 6), ('n_estimators', 70), ('num_leaves', 43)])\n",
      "\n",
      "Model #6\n",
      "Best ROC_AUC: 0.9837\n",
      "Best params: OrderedDict([('learning_rate', 0.2551996554556929), ('max_depth', 21), ('min_child_samples', 6), ('n_estimators', 70), ('num_leaves', 43)])\n",
      "\n",
      "Model #7\n",
      "Best ROC_AUC: 0.9837\n",
      "Best params: OrderedDict([('learning_rate', 0.2551996554556929), ('max_depth', 21), ('min_child_samples', 6), ('n_estimators', 70), ('num_leaves', 43)])\n",
      "\n",
      "Model #8\n",
      "Best ROC_AUC: 0.9837\n",
      "Best params: OrderedDict([('learning_rate', 0.2551996554556929), ('max_depth', 21), ('min_child_samples', 6), ('n_estimators', 70), ('num_leaves', 43)])\n",
      "\n",
      "Model #9\n",
      "Best ROC_AUC: 0.9837\n",
      "Best params: OrderedDict([('learning_rate', 0.2551996554556929), ('max_depth', 21), ('min_child_samples', 6), ('n_estimators', 70), ('num_leaves', 43)])\n",
      "\n",
      "Model #10\n",
      "Best ROC_AUC: 0.9837\n",
      "Best params: OrderedDict([('learning_rate', 0.2551996554556929), ('max_depth', 21), ('min_child_samples', 6), ('n_estimators', 70), ('num_leaves', 43)])\n",
      "\n",
      "Model #11\n",
      "Best ROC_AUC: 0.9837\n",
      "Best params: OrderedDict([('learning_rate', 0.2551996554556929), ('max_depth', 21), ('min_child_samples', 6), ('n_estimators', 70), ('num_leaves', 43)])\n",
      "\n",
      "Model #12\n",
      "Best ROC_AUC: 0.9837\n",
      "Best params: OrderedDict([('learning_rate', 0.2551996554556929), ('max_depth', 21), ('min_child_samples', 6), ('n_estimators', 70), ('num_leaves', 43)])\n",
      "\n",
      "Model #13\n",
      "Best ROC_AUC: 0.9837\n",
      "Best params: OrderedDict([('learning_rate', 0.2551996554556929), ('max_depth', 21), ('min_child_samples', 6), ('n_estimators', 70), ('num_leaves', 43)])\n",
      "\n",
      "Model #14\n",
      "Best ROC_AUC: 0.9837\n",
      "Best params: OrderedDict([('learning_rate', 0.2551996554556929), ('max_depth', 21), ('min_child_samples', 6), ('n_estimators', 70), ('num_leaves', 43)])\n",
      "\n",
      "Model #15\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #16\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #17\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #18\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #19\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #20\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #21\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #22\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #23\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #24\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #25\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #26\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #27\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #28\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #29\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #30\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #31\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #32\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #33\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #34\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #35\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #36\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #37\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #38\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #39\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #40\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #41\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #42\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #43\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #44\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #45\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #46\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #47\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #48\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #49\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #50\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #51\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #52\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #53\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #54\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #55\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #56\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #57\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #58\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #59\n",
      "Best ROC_AUC: 0.9838\n",
      "Best params: OrderedDict([('learning_rate', 0.10304111908436134), ('max_depth', 48), ('min_child_samples', 21), ('n_estimators', 100), ('num_leaves', 37)])\n",
      "\n",
      "Model #60\n",
      "Best ROC_AUC: 0.9844\n",
      "Best params: OrderedDict([('learning_rate', 0.13629132132482905), ('max_depth', 50), ('min_child_samples', 12), ('n_estimators', 100), ('num_leaves', 100)])\n",
      "\n",
      "Model #61\n",
      "Best ROC_AUC: 0.9844\n",
      "Best params: OrderedDict([('learning_rate', 0.13629132132482905), ('max_depth', 50), ('min_child_samples', 12), ('n_estimators', 100), ('num_leaves', 100)])\n",
      "\n",
      "Model #62\n",
      "Best ROC_AUC: 0.985\n",
      "Best params: OrderedDict([('learning_rate', 0.21200700601444025), ('max_depth', 28), ('min_child_samples', 8), ('n_estimators', 59), ('num_leaves', 40)])\n",
      "\n",
      "Model #63\n",
      "Best ROC_AUC: 0.985\n",
      "Best params: OrderedDict([('learning_rate', 0.21200700601444025), ('max_depth', 28), ('min_child_samples', 8), ('n_estimators', 59), ('num_leaves', 40)])\n",
      "\n",
      "Model #64\n",
      "Best ROC_AUC: 0.985\n",
      "Best params: OrderedDict([('learning_rate', 0.21200700601444025), ('max_depth', 28), ('min_child_samples', 8), ('n_estimators', 59), ('num_leaves', 40)])\n",
      "\n",
      "Model #65\n",
      "Best ROC_AUC: 0.985\n",
      "Best params: OrderedDict([('learning_rate', 0.21200700601444025), ('max_depth', 28), ('min_child_samples', 8), ('n_estimators', 59), ('num_leaves', 40)])\n",
      "\n",
      "Model #66\n",
      "Best ROC_AUC: 0.985\n",
      "Best params: OrderedDict([('learning_rate', 0.21200700601444025), ('max_depth', 28), ('min_child_samples', 8), ('n_estimators', 59), ('num_leaves', 40)])\n",
      "\n",
      "Model #67\n",
      "Best ROC_AUC: 0.985\n",
      "Best params: OrderedDict([('learning_rate', 0.21200700601444025), ('max_depth', 28), ('min_child_samples', 8), ('n_estimators', 59), ('num_leaves', 40)])\n",
      "\n",
      "Model #68\n",
      "Best ROC_AUC: 0.985\n",
      "Best params: OrderedDict([('learning_rate', 0.21200700601444025), ('max_depth', 28), ('min_child_samples', 8), ('n_estimators', 59), ('num_leaves', 40)])\n",
      "\n",
      "Model #69\n",
      "Best ROC_AUC: 0.985\n",
      "Best params: OrderedDict([('learning_rate', 0.21200700601444025), ('max_depth', 28), ('min_child_samples', 8), ('n_estimators', 59), ('num_leaves', 40)])\n",
      "\n",
      "Model #70\n",
      "Best ROC_AUC: 0.985\n",
      "Best params: OrderedDict([('learning_rate', 0.21200700601444025), ('max_depth', 28), ('min_child_samples', 8), ('n_estimators', 59), ('num_leaves', 40)])\n",
      "\n",
      "Model #71\n",
      "Best ROC_AUC: 0.985\n",
      "Best params: OrderedDict([('learning_rate', 0.21200700601444025), ('max_depth', 28), ('min_child_samples', 8), ('n_estimators', 59), ('num_leaves', 40)])\n",
      "\n",
      "Model #72\n",
      "Best ROC_AUC: 0.985\n",
      "Best params: OrderedDict([('learning_rate', 0.21200700601444025), ('max_depth', 28), ('min_child_samples', 8), ('n_estimators', 59), ('num_leaves', 40)])\n",
      "\n",
      "Model #73\n",
      "Best ROC_AUC: 0.985\n",
      "Best params: OrderedDict([('learning_rate', 0.21200700601444025), ('max_depth', 28), ('min_child_samples', 8), ('n_estimators', 59), ('num_leaves', 40)])\n",
      "\n",
      "Model #74\n",
      "Best ROC_AUC: 0.985\n",
      "Best params: OrderedDict([('learning_rate', 0.21200700601444025), ('max_depth', 28), ('min_child_samples', 8), ('n_estimators', 59), ('num_leaves', 40)])\n",
      "\n",
      "Model #75\n",
      "Best ROC_AUC: 0.985\n",
      "Best params: OrderedDict([('learning_rate', 0.21200700601444025), ('max_depth', 28), ('min_child_samples', 8), ('n_estimators', 59), ('num_leaves', 40)])\n",
      "\n",
      "Model #76\n",
      "Best ROC_AUC: 0.985\n",
      "Best params: OrderedDict([('learning_rate', 0.21200700601444025), ('max_depth', 28), ('min_child_samples', 8), ('n_estimators', 59), ('num_leaves', 40)])\n",
      "\n",
      "Model #77\n",
      "Best ROC_AUC: 0.985\n",
      "Best params: OrderedDict([('learning_rate', 0.21200700601444025), ('max_depth', 28), ('min_child_samples', 8), ('n_estimators', 59), ('num_leaves', 40)])\n",
      "\n",
      "Model #78\n",
      "Best ROC_AUC: 0.985\n",
      "Best params: OrderedDict([('learning_rate', 0.21200700601444025), ('max_depth', 28), ('min_child_samples', 8), ('n_estimators', 59), ('num_leaves', 40)])\n",
      "\n",
      "Model #79\n",
      "Best ROC_AUC: 0.985\n",
      "Best params: OrderedDict([('learning_rate', 0.21200700601444025), ('max_depth', 28), ('min_child_samples', 8), ('n_estimators', 59), ('num_leaves', 40)])\n",
      "\n",
      "Model #80\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n",
      "Model #81\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n",
      "Model #82\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n",
      "Model #83\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n",
      "Model #84\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n",
      "Model #85\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n",
      "Model #86\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n",
      "Model #87\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n",
      "Model #88\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #89\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n",
      "Model #90\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n",
      "Model #91\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n",
      "Model #92\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n",
      "Model #93\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n",
      "Model #94\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n",
      "Model #95\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n",
      "Model #96\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n",
      "Model #97\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n",
      "Model #98\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n",
      "Model #99\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n",
      "Model #100\n",
      "Best ROC_AUC: 0.9852\n",
      "Best params: OrderedDict([('learning_rate', 0.10955273917171476), ('max_depth', 0), ('min_child_samples', 12), ('n_estimators', 78), ('num_leaves', 100)])\n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EXECUTION TIME : hyperparameter_tuning ran in 328.26s\n"
     ]
    }
   ],
   "source": [
    "X, y = create_X_y_(oh_apis)\n",
    "\n",
    "lgb_model = LGBMClassifier(objective='binary', metric='auc', verbose=0)\n",
    "\n",
    "lgb_best_params = hyperparameter_tuning(X, y, \n",
    "                                       model = lgb_model, \n",
    "                                       tuning_params = tuning_params['LightGBM'],\n",
    "                                       scoring = 'roc_auc',\n",
    "                                       cv_strategy = cv_strategy,\n",
    "                                       n_settings = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "20e757b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EXECUTION TIME : score_model_dataset ran in 2.33s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.9483283010704141 ( +/- 0.011791962996857922 )\n"
     ]
    }
   ],
   "source": [
    "api_scores_ = score_model_dataset(oh_apis, LGBMClassifier(**lgb_best_params))\n",
    "print(f' {np.mean(api_scores_)} ( +/- {np.std(api_scores_)} )')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435a37f4",
   "metadata": {},
   "source": [
    "**Testing CatBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f21862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_X_y_(oh_apis)\n",
    "\n",
    "cat_model = CatBoostClassifier(thread_count=2, loss_function='Logloss', od_type = 'Iter', verbose= False)\n",
    "\n",
    "cat_best_params = hyperparameter_tuning(X, y, \n",
    "                                       model = cat_model, \n",
    "                                       tuning_params = tuning_params['CatBoost'],\n",
    "                                       scoring = 'accuracy',\n",
    "                                       cv_strategy = cv_strategy,\n",
    "                                       n_settings = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3a1d401b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EXECUTION TIME : score_model_dataset ran in 2.33s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.9483283010704141 ( +/- 0.011791962996857922 )\n"
     ]
    }
   ],
   "source": [
    "api_scores_ = score_model_dataset(oh_apis, CatBoostClassifier(**cat_best_params))\n",
    "print(f' {np.mean(api_scores_)} ( +/- {np.std(api_scores_)} )')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268be9c3",
   "metadata": {},
   "source": [
    "**Final implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6cd38fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timed\n",
    "def perform_nested_cv():\n",
    "    \n",
    "    cv_outer = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "    outer_results = { name : [] for name in tuning_params.keys()}\n",
    "\n",
    "    #X, y = create_X_y(folder_path, file_name)\n",
    "    X, y = create_X_y_(oh_api)\n",
    "\n",
    "    for train_ix, test_ix in cv_outer.split(X) :\n",
    "\n",
    "        X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "\n",
    "        cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "        ensemble_models = get_ensemble_models()\n",
    "\n",
    "        for name, model in ensemble_models.items():\n",
    "\n",
    "            best_params, best_model = hyperparameter_tuning(X_train = X_train, \n",
    "                                                            y_train = y_train, \n",
    "                                                            model = model, \n",
    "                                                            tuning_params = tuning_params[name], \n",
    "                                                            scoring = 'accuracy', \n",
    "                                                            cv_strategy = cv_inner, \n",
    "                                                            n_settings = 30,\n",
    "                                                            verbose = False,\n",
    "                                                            file_prefix = 'apistats_accuracy_30',\n",
    "                                                            best_model = True)\n",
    "\n",
    "\n",
    "            y_pred = best_model.predict(X_test)\n",
    "\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            outer_results[name].append(acc)\n",
    "\n",
    "    pickle_results(outer_results, 'apistats_accuracy_30.pickle')\n",
    "    \n",
    "    return outer_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaf9586",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_results = perform_nested_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfd7266",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_evaluation_boxplots(list(outer_results.values()), \n",
    "                               list(outer_results.keys()), \n",
    "                               title = 'Tunned Ensemble Model Performance On One-hot Encoded API Calls Data', \n",
    "                               y_axis = 'Accuracy')\n",
    "\n",
    "figure_path = 'figures/model-training-performance/encoded_apistats_bayes_accuracy_30.html'\n",
    "\n",
    "save_figures_to_html(figure_path, [fig])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

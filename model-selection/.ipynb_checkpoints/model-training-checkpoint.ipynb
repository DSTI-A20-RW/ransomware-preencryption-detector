{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81dd741",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e90f1400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b91d7e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "\n",
    "from numpy import hstack\n",
    "\n",
    "from IPython.display import IFrame\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "from plot_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5c172573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold, RepeatedStratifiedKFold, cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a45d5dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'C:/Users/yaass/OneDrive/Bureau/Parser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1e9fe763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(folder_path, file_name, index_value = 'md5'):\n",
    "    df = pd.read_csv(os.path.join(folder_path, file_name), index_col=index_value)\n",
    "    return df\n",
    "\n",
    "def print_proportion(df, label = 'label'):\n",
    "    print('Proportion : {:.2f}%'.format(100*sum(df.label)/len(df)))\n",
    "\n",
    "def create_X_y(folder_path, file_name, drop_null_columns=False, index_value = 'md5'):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    df = pd.read_csv(file_path, index_col = index_value)\n",
    "    X = df.drop('label', axis=1)\n",
    "    #X = df.drop(['label', 'sublabel'], axis=1)\n",
    "    if drop_null_columns == True:\n",
    "        X = X.drop(get_null_columns(X), axis=1)\n",
    "    y = df['label']\n",
    "    return shuffle(X, y)\n",
    "\n",
    "def create_X_y_(df, drop_null_columns=False, index_value = 'md5'):\n",
    "    X = df.drop('label', axis=1)\n",
    "    #X = df.drop(['label', 'sublabel'], axis=1)\n",
    "    if drop_null_columns == True:\n",
    "        X = X.drop(get_null_columns(X), axis=1)\n",
    "    y = df['label']\n",
    "    return shuffle(X, y)\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=2)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2665eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model_dataset(df, model):\n",
    "    X, y = create_X_y_(df)\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def join_dfs(dfs, labels=['label']):\n",
    "    joined = dfs[0]\n",
    "    for df in dfs[1:]:\n",
    "        joined = joined.join(df.drop(labels, axis=1)).fillna(0)\n",
    "    return joined\n",
    "\n",
    "\n",
    "def retrieve_subset(original_df, X, y = None, label='label', features_only=False):\n",
    "    filtered_columns = original_df.columns.tolist()\n",
    "    filtered_columns.remove(label)\n",
    "    if features_only == False :\n",
    "        filtered_index = original_df.index.intersection(X.index)\n",
    "        X_new = X.loc[filtered_index, filtered_columns]\n",
    "        y_new = y.loc[filtered_index]\n",
    "        return X_new, y_new\n",
    "    else :\n",
    "        X_new = X.loc[:, filtered_columns]\n",
    "        return X_new\n",
    "    \n",
    "    \n",
    "def prepare_datasets(original_dfs, X_train_full, X_test, y_train_full, y_test, test_size = 0.4):\n",
    "    datasets = []\n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(X_train_full, y_train_full, test_size = test_size, random_state = 1)\n",
    "    for df in original_dfs:\n",
    "        dataset = dict()\n",
    "        dataset['train'] = retrieve_subset(df, X_train, y_train)\n",
    "        dataset['eval'] = ( retrieve_subset(df, X_eval, features_only=True), y_eval )\n",
    "        dataset['test'] = ( retrieve_subset(df, X_test, features_only=True), y_test )\n",
    "        datasets.append(dataset)\n",
    "    return datasets\n",
    "    \n",
    "    \n",
    "def fit_ensemble(models, datasets):\n",
    "    X_meta = list()\n",
    "    for model, dataset in zip(models, datasets):\n",
    "        model.fit(*dataset['train'])\n",
    "        y_pred = model.predict(dataset['eval'][0])\n",
    "        y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "        X_meta.append(y_pred)\n",
    "    X_meta = np.hstack(X_meta)\n",
    "    blender = LogisticRegression()\n",
    "    blender.fit(X_meta, dataset['eval'][1])\n",
    "    return blender\n",
    "\n",
    "\n",
    "def predict_ensemble(models, blender, datasets):\n",
    "    X_meta = list()\n",
    "    for model, dataset in zip(models, datasets):\n",
    "        y_pred = model.predict(dataset['test'][0])\n",
    "        y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "        X_meta.append(y_pred)\n",
    "    X_meta = np.hstack(X_meta)\n",
    "    return blender.predict(X_meta)\n",
    "\n",
    "\n",
    "def get_blender_accuracy(original_dfs, X_train_full, X_test, y_train_full, y_test, models):\n",
    "    datasets = prepare_datasets(original_dfs, X_train_full, X_test, y_train_full, y_test, test_size = 0.4)\n",
    "    blender = fit_ensemble(models, datasets)\n",
    "    y_pred = predict_ensemble(models, blender, datasets)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80e3881",
   "metadata": {},
   "source": [
    "### API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bcf7d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3761, 304)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_1 = 'onehot_encoded_apistats_dataset.csv'\n",
    "\n",
    "oh_apis = get_data(folder_path, file_name_1)\n",
    "\n",
    "oh_apis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09c00656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion : 58.23%\n"
     ]
    }
   ],
   "source": [
    "print_proportion(oh_apis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1c31dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute api cross-validation accuracy scores\n",
    "api_scores = score_model_dataset(oh_apis, RandomForestClassifier())\n",
    "np.mean(api_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d275ae0",
   "metadata": {},
   "source": [
    "### DLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df3d79fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3162, 2242)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_2 = 'onehot_encoded_dll_dataset.csv'\n",
    "\n",
    "dll_loaded = get_data(folder_path, file_name_2)\n",
    "\n",
    "dll_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af0d6a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion : 58.82%\n"
     ]
    }
   ],
   "source": [
    "print_proportion(dll_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "25a39af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute dll cross-validation accuracy scores\n",
    "dll_scores = score_model_dataset(dll_loaded, RandomForestClassifier())\n",
    "np.mean(dll_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c934c9d1",
   "metadata": {},
   "source": [
    "### PE Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5692d926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4308, 795)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_3 = 'pe_entropy_dataset.csv'\n",
    "\n",
    "pe_imports = get_data(folder_path, file_name_3)\n",
    "\n",
    "if 'sublabel' in pe_imports.columns.tolist():\n",
    "    pe_imports.drop('sublabel', axis=1, inplace=True)\n",
    "\n",
    "pe_imports.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b709affd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion : 60.35%\n"
     ]
    }
   ],
   "source": [
    "print_proportion(pe_imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e8eb79b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9030475368262021"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute pe_imports cross-validation accuracy scores\n",
    "pe_imports_scores = score_model_dataset(pe_imports, RandomForestClassifier())\n",
    "np.mean(pe_imports_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef892682",
   "metadata": {},
   "source": [
    "## Joining Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dfdbca",
   "metadata": {},
   "source": [
    "### API and DLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "99b7fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dfs = [oh_apis, dll_loaded]\n",
    "\n",
    "joined_ = join_dfs(original_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe8f20a",
   "metadata": {},
   "source": [
    "#### Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98dcdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "joining_scores = score_model_dataset(joined_, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e10f10",
   "metadata": {},
   "source": [
    "#### Blending"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2760bcb",
   "metadata": {},
   "source": [
    "*Train-Test-Split*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4381b2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blending Accuracy: 0.947\n"
     ]
    }
   ],
   "source": [
    "X, y = create_X_y_(joined_)\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size = 0.1, random_state = 1)\n",
    "\n",
    "models = [RandomForestClassifier(), RandomForestClassifier()]\n",
    "\n",
    "score = get_blender_accuracy(original_dfs, X_train_full, X_test, y_train_full, y_test, models)\n",
    "\n",
    "print('Blending Accuracy: %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4efefb3",
   "metadata": {},
   "source": [
    "*Cross-validation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d7c60210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9357469383148033"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "models = [RandomForestClassifier(), RandomForestClassifier()]\n",
    "\n",
    "blending_scores = []\n",
    "\n",
    "X, y = create_X_y_(joined_)\n",
    "\n",
    "for train_index, test_index in CV.split(X, y):\n",
    "    X_train_full, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    y_train_full, y_test = y[train_index], y[test_index]\n",
    "    score = get_blender_accuracy(original_dfs, X_train_full, X_test, y_train_full, y_test, models)\n",
    "    blending_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6602cd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"600\"\n",
       "            src=\"joined/evaluation_joined_api_dll.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x29b04229fd0>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plot_evaluation_boxplots([api_scores, dll_scores, accuracy_scores, joining_scores], \n",
    "                               names = ['API', 'DLL', 'Blended', 'Joined'], \n",
    "                               title = 'Model Performance on joined \"apistats\" and \"dll\" Data', \n",
    "                               y_axis = 'Accuracy')\n",
    "\n",
    "figure_path = 'joined/evaluation_joined_api_dll.html'\n",
    "\n",
    "save_figures_to_html(figure_path, [fig])\n",
    "\n",
    "IFrame(figure_path, width=900, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f243713f",
   "metadata": {},
   "source": [
    "### API and PE Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fd577a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dfs = [pe_imports, oh_apis]\n",
    "\n",
    "joined = join_dfs(original_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3243cd16",
   "metadata": {},
   "source": [
    "#### Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "821d9f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "joining_scores = score_model_dataset(joined, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46c7e86",
   "metadata": {},
   "source": [
    "#### Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "78a60159",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "models = [RandomForestClassifier(), RandomForestClassifier()]\n",
    "\n",
    "blending_scores = []\n",
    "\n",
    "X, y = create_X_y_(joined)\n",
    "\n",
    "for train_index, test_index in CV.split(X, y):\n",
    "    X_train_full, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    y_train_full, y_test = y[train_index], y[test_index]\n",
    "    score = get_blender_accuracy(original_dfs, X_train_full, X_test, y_train_full, y_test, models)\n",
    "    blending_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c2cd3033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"600\"\n",
       "            src=\"joined/evaluation_joined_api_pe_imports.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x29b0ff05af0>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plot_evaluation_boxplots([api_scores, pe_imports_scores, blending_scores, joining_scores], \n",
    "                               names = ['API', 'PE Imports', 'Blended', 'Joined'], \n",
    "                               title = 'Model Performance on joined \"apistats\" and \"pe imports\" Data', \n",
    "                               y_axis = 'Accuracy')\n",
    "\n",
    "figure_path = 'joined/evaluation_joined_api_pe_imports.html'\n",
    "\n",
    "save_figures_to_html(figure_path, [fig])\n",
    "\n",
    "IFrame(figure_path, width=900, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8483ad82",
   "metadata": {},
   "source": [
    "#### Nested cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f18028ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "outer_results = { 'accuracy' : [], 'best_params' : [] }\n",
    "\n",
    "#X, y = create_X_y(folder_path, file_name)\n",
    "X, y = create_X_y_(joined)\n",
    "\n",
    "for train_ix, test_ix in cv_outer.split(X) :\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
    "    y_train, y_test = y[train_ix], y[test_ix]\n",
    "    \n",
    "    cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    \n",
    "    pipe = Pipeline(steps=[('kbest', SelectKBest(f_classif, k=5)), ('rf', RandomForestClassifier(random_state=1))])\n",
    "    \n",
    "    model = RandomForestClassifier(random_state=1)\n",
    "    \n",
    "    grid = dict()\n",
    "    grid['rf__n_estimators'] = [50, 100, 150, 200]\n",
    "    grid['rf__max_features'] = [10, 20, 'sqrt', 'log2']\n",
    "    #grid['kbest__k'] = [10, 20, 30, 50]\n",
    "    #grid['kbest__score_func'] = [f_classif, chi2]\n",
    "    \n",
    "    space = dict()\n",
    "    space['n_estimators'] = [50, 100, 150, 200]\n",
    "    space['max_features'] = [10, 20, 'sqrt', 'log2']\n",
    "    \n",
    "    search = GridSearchCV(model, space, scoring='accuracy', cv=cv_inner, refit=True)\n",
    "    \n",
    "    result = search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = result.best_estimator_\n",
    "    best_params = result.best_params_\n",
    "\n",
    "    yhat = best_model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "\n",
    "    outer_results['accuracy'].append(acc)\n",
    "    outer_results['best_params'].append(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90353dc",
   "metadata": {},
   "source": [
    "**API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29b13d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9460254529036629"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(outer_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b586239b",
   "metadata": {},
   "source": [
    "**API avec SelectKBest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67cd2914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8921939212658213"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(outer_results['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6cd9a5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kbest__k': 50,\n",
       " 'kbest__score_func': <function sklearn.feature_selection._univariate_selection.f_classif(X, y)>,\n",
       " 'rf__n_estimators': 200}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = outer_results['accuracy']\n",
    "max_ix = [i for i, x in enumerate(accuracies) if x == max(accuracies)]\n",
    "outer_results['best_params'][max_ix[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
